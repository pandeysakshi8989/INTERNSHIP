# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XO-SRwp8Y_quAnMUTWpsr9vhdButlnbN
"""

import pandas as pd
from nltk.stem.porter import PorterStemmer

#from google.colab import drive
#drive.mount('/content/drive')

import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

df = pd.read_csv('/content/Restaurant_Reviews 1.tsv', delimiter = '\t', quoting =3)

df.head()

df.shape

df["Review"][0]

df.info()

df.columns

import re
#import string

corpus = []
for i in range(0,1000):
  review = re.sub(pattern = '[^a-zA-Z]', repl =' ', string =df['Review'][i])
  review= review.lower()
  review_word = review.split()
  review_word = [word for word in review_word if not word in set(stopwords.words('english'))]
  ps = PorterStemmer()
  review1 = [ps.stem(word) for word in review_word]
  #Join the stemmed words back into a single string
  review = ' '.join(review1)
  corpus.append(review)

set (stopwords.words('english'))

corpus[:1000]

df.shape

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)

tfid_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names_out())
print(tfid_df.tail(30))

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=1500)

df['review']

X = cv.fit_transform(corpus).toarray()

X.shape

X[0]

X[0].max()

y= df.iloc[:,1].values.astype(int) # Convert y to integer type

#y= df.iloc[:,1].values

y.shape

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=104)

from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB

clf1 = GaussianNB()
clf2 = MultinomialNB()
clf3 = BernoulliNB()

clf1.fit(X_train,y_train)
clf2.fit(X_train,y_train)
clf3.fit(X_train,y_train)

y_predG = clf1.predict(X_test)
y_predM = clf2.predict(X_test)
y_predB = clf3.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_predG)

accuracy_score(y_test,y_predM)

accuracy_score(y_test,y_predB)

print("Gussian",accuracy_score(y_test,y_predG))
print("Multinomial",accuracy_score(y_test,y_predM))
print("Bernoulli",accuracy_score(y_test,y_predB))

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_predM)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Multinomial Naive Bayes')
plt.show()

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
etc = ExtraTreesClassifier(n_estimators=100, random_state=0)

etc.fit(X_train, y_train)

y_pred_etc = etc.predict(X_test)

accuracy_etc = accuracy_score(y_test, y_pred_etc)
print(f"ExtraTreesClassifier Accuracy: {accuracy_etc}")

cm_etc = confusion_matrix(y_test, y_pred_etc)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_etc, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for ExtraTreesClassifier')
plt.show()

from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
xgb_clf = XGBClassifier(random_state=0)
xgb_clf.fit(X_train, y_train)

y_pred_xgb = xgb_clf.predict(X_test)

accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
print(f"XGBoost Classifier Accuracy: {accuracy_xgb}")

cm_xgb = confusion_matrix(y_test, y_pred_xgb)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for XGBoost Classifier')
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
rfc = RandomForestClassifier(n_estimators=100, random_state=0)

rfc.fit(X_train, y_train)

y_pred_rfc = rfc.predict(X_test)

accuracy_rfc = accuracy_score(y_test, y_pred_rfc)
print(f"RandomForestClassifier Accuracy: {accuracy_rfc}")

cm_rfc = confusion_matrix(y_test, y_pred_rfc)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_rfc, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for RandomForestClassifier')
plt.show()

import pandas as pd
from nltk.stem.porter import PorterStemmer
import nltk
from nltk.corpus import stopwords
import re
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

nltk.download('stopwords')

df = pd.read_csv('/content/Restaurant_Reviews 1.tsv', delimiter = '\t', quoting =3)

corpus = []
for i in range(0,1000):
  review = re.sub(pattern = '[^a-zA-Z]', repl =' ', string =df['Review'][i])
  review= review.lower()
  review_word = review.split()
  review_word = [word for word in review_word if not word in set(stopwords.words('english'))]
  ps = PorterStemmer()
  review1 = [ps.stem(word) for word in review_word]
  review = ' '.join(review1)
  corpus.append(review)

tfidf = TfidfVectorizer(max_features=1500)
X = tfidf.fit_transform(corpus).toarray()
y= df.iloc[:,1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=104)

clf1 = GaussianNB()
clf2 = MultinomialNB()
clf3 = BernoulliNB()

clf1.fit(X_train,y_train)
clf2.fit(X_train,y_train)
clf3.fit(X_train,y_train)

y_predG = clf1.predict(X_test)
y_predM = clf2.predict(X_test)
y_predB = clf3.predict(X_test)

print("Gussian",accuracy_score(y_test,y_predG))
print("Multinomial",accuracy_score(y_test,y_predM))
print("Bernoulli",accuracy_score(y_test,y_predB))

cm = confusion_matrix(y_test, y_predM)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix for Multinomial Naive Bayes')
plt.show()

import pandas as pd
from nltk.stem.porter import PorterStemmer

df_rfid = pd.read_csv('/content/Restaurant_Reviews 1.tsv', delimiter='\t', on_bad_lines='skip')

def process_rfid(rfid_tag):
    processed_data = f"Processed: {rfid_tag}"
    return processed_data

df_rfid['processed_rfid'] = df_rfid['Review'].apply(process_rfid)

print(df_rfid)

def is_valid_rfid(rfid_tag):
    return len(str(rfid_tag)) == 10 and str(rfid_tag).isdigit()

df_rfid['valid'] = df_rfid['Review'].apply(is_valid_rfid)
df_rfid

