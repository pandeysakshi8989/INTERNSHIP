{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQFgSMMS1yEp",
        "outputId": "0bba0efa-4c21-4c32-dc19-de675de066a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"I loved the movie! It was amazing. 10/ 10 : )\",\n",
        "    \"The movie was terrible. Waste of time !!\",\n",
        "    \"A masterpiece of storytellying. Would watch again.\",\n",
        "]\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(rf\"[{string.punctuation}]\",\" \", text)\n",
        "    text = re.sub(r\"\\d+\", \" \", text) #Remove numbers\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "preprocessed_docs = [preprocess_text(doc) for doc in docs]\n",
        "\n",
        "for i , doc in enumerate(preprocessed_docs):\n",
        "    print(f\"Original Document {i+1}: {docs[i]}\")\n",
        "    print(f\"Preprocessed Document {i+1}: {doc}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E8U7D932mWp",
        "outputId": "bda3e7c7-5f36-4668-cfb5-53e93c0a22e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Document 1: I loved the movie! It was amazing. 10/ 10 : )\n",
            "Preprocessed Document 1: loved movie amazing\n",
            "--------------------------------------------------\n",
            "Original Document 2: The movie was terrible. Waste of time !!\n",
            "Preprocessed Document 2: movie terrible waste time\n",
            "--------------------------------------------------\n",
            "Original Document 3: A masterpiece of storytellying. Would watch again.\n",
            "Preprocessed Document 3: masterpiece storytellying would watch\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "docs = [\"I love programming.\", \"Programming is fun! \", \"I love fun activities.\"]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(docs)\n",
        "\n",
        "print(\"Vocabulary: \",vectorizer.get_feature_names_out())\n",
        "print(\"Encoded Matrix: \\n\",X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5L1MCM_8Zt9",
        "outputId": "16e6c066-dbd9-454e-dbcb-7b811ace6dda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:  ['activities' 'fun' 'is' 'love' 'programming']\n",
            "Encoded Matrix: \n",
            " [[0 0 0 1 1]\n",
            " [0 1 1 0 1]\n",
            " [1 1 0 1 0]]\n"
          ]
        }
      ]
    }
  ]
}